Functional testing
==================

This document describes the implementation of the functional tests in AeoLiS.


Functional tests overview
-------------------------

- Functional testing is a type of black-box testing where the software as a whole is tested by feeding it input and examining the output, and internal program structure is rarely considered.
- Functional testing usually describes what the system does.
- Functional testing does not imply that you are testing a function (method) of a module or class. Functional testing tests a slice of functionality of the whole system. 


Functional testing in Aeolis
----------------------------

AeoLiS has currently two functional tests:

- `test_netCDF_content.py`: tests whether the content of the netCDF files generated by the latest version of AeoLiS for a given input file is the same as the content of the netCDF files generated by the previous version of AeoLiS for the same input file.

- `test_netCDF_creation.py`: Tests whether a netCDF file is created upon a successful execution of the model. 


(Replace with walking through one of the two functional tests)
Functional tests in aeolis are implemented   : (replace with a flowchart)

- Arrange: Prepare the test environment. This includes:
    - Locate the input file for the simulation
- Act: Kick-off the behavior we want to test, i.e., start the simulation for the given input file
- Assert: Check if results are as expected:
    - For the test test_netCDF_creation, check whether Aeolis.nc and Aeolis.log are created in the same folder as the input file. For the tests
    - For the test_netCDF_content, check whether the content of the netcdf file is the same as the content of the netcdf file generated by the previous version of the model. 
- Cleanup: Delete the generated netcdf and log files to ensure that the test environment is clean for the next test.

- [To do]: Add a point about test inputs and reference outputs


Writing Functional Tests
------------------------

- Follow the first two steps as described in unti testing writing guide.

(This point may be too much detail)
- Separate the test resources needed by the tests from each other. Since functional tests in Aeolis would ideally require the simulation to run, make sure that each test has its own test environment. Do not combine functional tests in a for loop. This is to ensure that the tests are independent and do not affect each other and have fresh access to the initial conditions and resources it needs to run. This might lead to a time penalty since the same setup and tear down operation would need to be done for each test, but it is important to ensure that the tests are independent of each other. For an example, the two functional tests in aeolis involve a setup part where the simulation is run and then a tear down part where the generated files are deleted. This is done for each test case. This ensures that the tests are independent of each other and do not affect each other.



Implementation of functional tests using Fixtures
-------------------------------------------------

(Couple this with short bullet points when describing the functional test implementation in the previous section)

Fixtures from pytest has been used to implement the functional tests. Fixtures are functions that are called by pytest before the actual test is executed. Fixtures are used to setup the test environment. In the case of the functional tests, the fixtures are used to setup the input files and the output files. The fixtures are defined in the file `conftest.py`. The fixtures are called by the test functions in the file `test_netCDF_content.py` and `test_netCDF_creation.py`.

Since fucntional tests test the system as a whole as a black box, every test case/scenario needs to be setup from scratch. This means that the input files and the output files need to be created for every test case/scenario. This is done by the fixtures. We use fixtures for this for writing organized code. The fixtures are called by the test functions. The fixtures are defined in the file `conftest.py`. The fixtures are called by the test functions in the file `test_netCDF_content.py` and `test_netCDF_creation.py`.


What to do in the event of a test failure
-----------------------------------------
(This section may not be relevant to add)
- Check error log of the failed github action 


Important note on the implementation of the functional tests
------------------------------------------------------------
(Couple this point with the test input and reference output bullet in the implementation section)

Do not change the contents of the inputs folder inside tests. This is where the sample inputs and reference results lives which is used by the tests. Thetests are benchmarked for these inputs. CHanging them will result in tests failures. The existing fucntional tests are only valid as long as you do not make any breaking changes in the way you do the calculations. In that case, the tests will fail, so discuss within the team if there is a genuine need to update the tests. This should only be in the case when you agree as a team that the way the previous simulatons were run is not valied naymore due to a change in the calcuations which would render the olde results invalid. 




